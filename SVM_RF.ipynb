{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "27779c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import warnings\n",
    "from gensim.models import KeyedVectors\n",
    " \n",
    "warnings.filterwarnings(action = 'ignore')\n",
    " \n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import heapq\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from scipy.stats import norm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import re\n",
    "import sys\n",
    "import random\n",
    "import heapq\n",
    "import ipynb.fs  \n",
    "sys.path.append(\"../\")\n",
    "from .defs.get_abstract_2 import count_shared_papers\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5be2b7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../MADStat-dataset-final-version/data.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "'''load list of authors'''\n",
    "with open('../author_name.txt') as f:\n",
    "    authors = f.readlines()\n",
    "authors = [author.strip() for author in authors]\n",
    "\n",
    "'''load papers info'''\n",
    "papers = pd.read_csv(\"../paper.csv\")\n",
    "\n",
    "\"\"\"load list of authors having at least 30 papers\"\"\"\n",
    "with open(\"../../authors\",\"rb\") as fp:\n",
    "    author_l = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f82d6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(data) :\n",
    "        #data.text = data.text.apply(remove_hexa_symbols)\n",
    "        #data.text = data.text.apply(remove_digits)\n",
    "        data = data.filter(['author', 'title', 'text']).rename(columns = {'title' : 'doc_id'})\n",
    "        data[\"len\"] = data.text.apply(lambda x: len(x))\n",
    "        data.text = data.text.apply(lambda x: re.sub(\"All rights\",\"\",x))\n",
    "        data.text = data.text.apply(lambda x: re.sub(\"reserved\",\"\",x))\n",
    "#         data.text = data.text.apply(lambda x: re.sub(\"[0-9]\",\"\",x))\n",
    "        data.text = data.text.apply(lambda x: re.sub(\"[^A-Za-z ]\",\"\",x))\n",
    "        data.text = data.text.apply(lambda x: re.sub(\"copyright\",\"\",x))\n",
    "        data.text = data.text.apply(lambda x: x.lower())\n",
    "        data = data.loc[data.len > 10].reset_index()\n",
    "        data.drop(columns=[\"len\"],inplace=True)\n",
    "        return data\n",
    "    \n",
    "def topKFrequent(nums, k):\n",
    "    dic=Counter(nums)\n",
    "    heapmax=[[-freq,num] for num,freq in dic.items()]\n",
    "    heapq.heapify(heapmax)\n",
    "    list1=[]\n",
    "    for i in range(k):\n",
    "        poping=heapq.heappop(heapmax)\n",
    "        list1.append(poping[1])\n",
    "    return list1\n",
    "\n",
    "\n",
    "def get_vocab(text, max_length=200):\n",
    "#     clf = CountVectorizer(lowercase=True)\n",
    "#     clf.fit([text])\n",
    "#     vocab = list(clf.vocabulary_.keys())\n",
    "#     print(\"vocab before = \",vocab)\n",
    "    vocab_f = []\n",
    "    vocab = text.split()\n",
    "    for word in set(vocab):\n",
    "        if word in model:\n",
    "            vocab_f.append(word)\n",
    "    return vocab_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c50b3a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Reinaldo B. Arellano-valle versus Howell Tong is 0.23076923076923078 with f1 score 0.23076923076923078\n",
      "Accuracy of Hammou El Barmi versus James O. Ramsay is 0.21052631578947367 with f1 score 0.28571428571428564\n",
      "Accuracy of Amir Dembo versus John Crowley is 0.42857142857142855 with f1 score 0.5384615384615384\n",
      "Accuracy of Jan Beirlant versus Gang 2 Li is 0.55 with f1 score 0.64\n",
      "Accuracy of Paul Yip versus Heng Lian is 0.3157894736842105 with f1 score 0.3157894736842105\n",
      "Accuracy of Michael Kohler versus Francesca Dominici is 0.2857142857142857 with f1 score 0.2857142857142857\n",
      "Accuracy of Allan Gut versus Andrew Wood is 0.5909090909090909 with f1 score 0.64\n",
      "Accuracy of Carlos Matrán versus Runze Li is 0.5333333333333333 with f1 score 0.5625\n",
      "Accuracy of Ruben Zamar versus Masanobu Taniguchi is 0.5185185185185185 with f1 score 0.5185185185185185\n",
      "Accuracy of Fabienne Comte versus Theo Gasser is 0.3333333333333333 with f1 score 0.2222222222222222\n",
      "Accuracy of Mohsen Pourahmadi versus Paul Janssen is 0.21739130434782608 with f1 score 0.18181818181818182\n",
      "Accuracy of Yingcun Xia versus Yaacov Ritov is 0.5217391304347826 with f1 score 0.56\n",
      "Accuracy of Thomas Scheike versus Randy Eubank is 0.4583333333333333 with f1 score 0.380952380952381\n",
      "Accuracy of Jing Qin versus John Kent is 0.35135135135135137 with f1 score 0.42857142857142855\n",
      "Accuracy of Lu Lin versus Dimitris Politis is 0.5 with f1 score 0.5384615384615385\n",
      "Accuracy of Stijn Vansteelandt versus Hongtu Zhu is 0.5357142857142857 with f1 score 0.5517241379310345\n",
      "Accuracy of James R. Schott versus Yufeng Liu is 0.5 with f1 score 0.5217391304347826\n",
      "Accuracy of Robert Serfling versus Thomas M. Liggett is 0.42105263157894735 with f1 score 0.5217391304347826\n",
      "Accuracy of David Siegmund versus Edward L. Korn is 0.4482758620689655 with f1 score 0.5\n",
      "Accuracy of Hélène Massam versus Claudio Landim is 0.5 with f1 score 0.5454545454545454\n",
      "Accuracy of Anthony C. Atkinson versus Fernando Quintana is 0.5862068965517241 with f1 score 0.6470588235294118\n",
      "Accuracy of A. Philip Dawid versus Kanti V. Mardia is 0.5 with f1 score 0.45161290322580644\n",
      "Accuracy of Tony Cai versus Bernard Rosner is 0.5405405405405406 with f1 score 0.6046511627906976\n",
      "Accuracy of Bingyi Jing versus Francisco J. Samaniego is 0.5384615384615384 with f1 score 0.6\n",
      "Accuracy of Gerda Claeskens versus Mohsen Pourahmadi is 0.375 with f1 score 0.4\n",
      "Accuracy of Theo Gasser versus Harold Sackrowitz is 0.32142857142857145 with f1 score 0.2962962962962963\n",
      "Accuracy of Roderick Little versus Arthur Cohen is 0.34146341463414637 with f1 score 0.425531914893617\n",
      "Accuracy of Stuart G. Baker versus Josemar Rodrigues is 0.55 with f1 score 0.47058823529411764\n",
      "Accuracy of A. Philip Dawid versus Mohammad Z. Raqab is 0.5652173913043478 with f1 score 0.6428571428571429\n",
      "Accuracy of Bernard Rosner versus R. J. Martin is 0.28 with f1 score 0.3076923076923077\n",
      "Accuracy of Ole Barndorff-nielsen versus John Klein is 0.4074074074074074 with f1 score 0.42857142857142855\n",
      "Accuracy of Alan Hutson versus Aurore Delaigle is 0.5357142857142857 with f1 score 0.5806451612903225\n",
      "Accuracy of Stijn Vansteelandt versus Daniel F. Heitjan is 0.5238095238095238 with f1 score 0.5454545454545454\n",
      "Accuracy of Mei-cheng Wang versus Peter Bauer is 0.3333333333333333 with f1 score 0.41666666666666663\n",
      "Accuracy of Steve 1 Brooks versus Edward L. Korn is 0.5217391304347826 with f1 score 0.4210526315789474\n",
      "Accuracy of Aurore Delaigle versus Faming Liang is 0.25 with f1 score 0.24999999999999994\n",
      "Accuracy of Hulin Wu versus Ian White is 0.5 with f1 score 0.4615384615384615\n",
      "Accuracy of Subhashis Ghosal versus Dankmar Böhning is 0.4074074074074074 with f1 score 0.42857142857142855\n",
      "Accuracy of Willi Sauerbrei versus Fabienne Comte is 0.5263157894736842 with f1 score 0.5263157894736842\n",
      "Accuracy of Christos Koukouvinos versus Dianne M. Finkelstein is 0.5925925925925926 with f1 score 0.7317073170731707\n",
      "Accuracy of Subhashis Ghosal versus John P. Morgan is 0.36 with f1 score 0.42857142857142855\n",
      "Accuracy of Joseph L. Gastwirth versus Harry Joe is 0.3783783783783784 with f1 score 0.43902439024390244\n",
      "Accuracy of Haibo Zhou versus Cyrus Mehta is 0.5416666666666666 with f1 score 0.4761904761904762\n",
      "Accuracy of Reinaldo B. Arellano-valle versus Xian Zhou is 0.5416666666666666 with f1 score 0.6206896551724139\n",
      "Accuracy of Luc Devroye versus Richard Johnson is 0.4117647058823529 with f1 score 0.5238095238095238\n",
      "Accuracy of Takeaki Kariya versus Aloke Dey is 0.45 with f1 score 0.4210526315789474\n",
      "Accuracy of Anthony Ohagan versus G. A. Young is 0.55 with f1 score 0.5263157894736842\n",
      "Accuracy of Madan Puri versus Zhi Geng is 0.5483870967741935 with f1 score 0.631578947368421\n",
      "Accuracy of André I. Khuri versus Doug Nychka is 0.391304347826087 with f1 score 0.4615384615384615\n",
      "Accuracy of Rudolf Beran versus Colin B. Begg is 0.5384615384615384 with f1 score 0.6470588235294118\n",
      "Accuracy of Li Hsu versus Doug Nychka is 0.42105263157894735 with f1 score 0.47619047619047616\n",
      "Accuracy of Jeffrey Hart versus Alastair Scott is 0.30434782608695654 with f1 score 0.27272727272727276\n",
      "Accuracy of Giovanni Parmigiani versus Carlos Matrán is 0.5 with f1 score 0.5714285714285714\n",
      "Accuracy of Joseph L. Gastwirth versus Wing Fung is 0.5 with f1 score 0.5957446808510639\n",
      "Accuracy of Yanyuan Ma versus C. Radhakrishna Rao is 0.32432432432432434 with f1 score 0.2857142857142857\n",
      "Accuracy of John Stufken versus Gemai Chen is 0.43478260869565216 with f1 score 0.5806451612903226\n",
      "Accuracy of Nitis Mukhopadhyay versus Hongtu Zhu is 0.48148148148148145 with f1 score 0.36363636363636365\n",
      "Accuracy of Claudia Czado versus István Berkes is 0.3684210526315789 with f1 score 0.4545454545454546\n",
      "Accuracy of Thomas Scheike versus Sin-ho Jung is 0.5 with f1 score 0.4444444444444444\n",
      "Accuracy of Tachen Liang versus Anastasios Tsiatis is 0.5641025641025641 with f1 score 0.41379310344827586\n",
      "Accuracy of Jon Wakefield versus Thomas P. Hettmansperger is 0.4838709677419355 with f1 score 0.5789473684210527\n",
      "Accuracy of Jane-ling Wang versus Jianguo 1 Sun is 0.40540540540540543 with f1 score 0.35294117647058826\n",
      "Accuracy of Arthur Cohen versus Jason Fine is 0.4222222222222222 with f1 score 0.4999999999999999\n",
      "Accuracy of Stephen Lee versus Sigeo Aki is 0.4583333333333333 with f1 score 0.48\n",
      "Accuracy of Garrett Fitzmaurice versus Ian Dryden is 0.5185185185185185 with f1 score 0.5517241379310345\n",
      "Accuracy of Kanti V. Mardia versus Wenceslao González-manteiga is 0.5238095238095238 with f1 score 0.5652173913043478\n",
      "Accuracy of Ruben Zamar versus Jayanta K. Ghosh is 0.3548387096774194 with f1 score 0.23076923076923075\n"
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "    author1 = random.choice(author_l)\n",
    "    author2 = random.choice(author_l)\n",
    "    \n",
    "    author_1 = pd.read_csv(f'../Data/{author1}.csv').filter(['author', 'title', 'text'])\n",
    "    author_2 = pd.read_csv(f'../Data/{author2}.csv').filter(['author', 'title', 'text'])\n",
    "    n, m = author_1.shape[0], author_2.shape[0]\n",
    "    if author1 != author2 and count_shared_papers(author1,author2,authors,data)==0 and min(n/m, m/n) >= 1/2:   \n",
    "        data_ = pd.concat([clean_text(author_1),\n",
    "                                          clean_text(author_2)], ignore_index=True)\n",
    "\n",
    "        data_train = data_.sample(frac=0.7)\n",
    "        data_test = data_.drop(data_train.index)\n",
    "        vocab = get_vocab(''.join([doc + \" \" for doc in list(data_train[\"text\"])]), max_length=400)\n",
    "\n",
    "\n",
    "        text1 = data_train[data_train[\"author\"]==author1]\n",
    "        text2 = data_train[data_train[\"author\"]==author2]\n",
    "\n",
    "\n",
    "\n",
    "        n, m = text1.shape[0], text2.shape[0]\n",
    "        embed = np.zeros((n+m,300))\n",
    "        for i in range(n):\n",
    "            embed[i,:] = doc_to_vec(text1.text.iloc[i],vocab)\n",
    "        for j in range(n,n+m):\n",
    "            embed[j,:] = doc_to_vec(text2.text.iloc[j-n],vocab)\n",
    "            \n",
    "        pca = PCA(n_components=10)\n",
    "        X_train = pca.fit_transform(embed)\n",
    "        y_train = np.concatenate((np.ones(n),np.zeros(m)))\n",
    "        \n",
    "        \n",
    "        t1 = data_test[data_test[\"author\"]==author1]\n",
    "        t2 = data_test[data_test[\"author\"]==author2]\n",
    "\n",
    "        nt, mt = t1.shape[0], t2.shape[0]\n",
    "        embed_t = np.zeros((nt+mt,300))\n",
    "        for i in range(nt):\n",
    "            embed_t[i,:] = doc_to_vec(t1.text.iloc[i],vocab)\n",
    "        for j in range(nt,nt+mt):\n",
    "            embed_t[j,:] = doc_to_vec(t2.text.iloc[j-nt],vocab)\n",
    "            \n",
    "        X_test = pca.transform(embed_t)\n",
    "        y_test = np.concatenate((np.ones(nt),np.zeros(mt)))\n",
    "        y_pred = clf.predict(X_test)\n",
    "        score = clf.score(X_test,y_test)\n",
    "        f1 = f1_score(y_pred,y_test)\n",
    "        if score <= 0.6:\n",
    "            print(f\"Accuracy of {author1} versus {author2} is {score} with f1 score {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a7f10411",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "17586c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_to_vec(doc,vocab):\n",
    "    cur = np.zeros(300)\n",
    "    i = 0\n",
    "    for word in doc.split():\n",
    "        if word in vocab:\n",
    "            i+=1\n",
    "            cur+=model[word]\n",
    "    return cur/i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "148b140c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 10)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=10)\n",
    "X = pca.fit_transform(embed)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9fa4c3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47,)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.concatenate((np.ones(n),np.zeros(m)))\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "fd2ff28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7a27d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = data_test[data_test[\"author\"]==author1]\n",
    "t2 = data_test[data_test[\"author\"]==author2]\n",
    "\n",
    "nt, mt = t1.shape[0], t2.shape[0]\n",
    "embed_t = np.zeros((nt+mt,300))\n",
    "for i in range(nt):\n",
    "    embed_t[i,:] = doc_to_vec(t1.text.iloc[i],vocab)\n",
    "for j in range(nt,nt+mt):\n",
    "    embed_t[j,:] = doc_to_vec(t2.text.iloc[j-nt],vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2f361d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pca.transform(embed_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f99bba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.concatenate((np.ones(nt),np.zeros(mt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3992e07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5e8ee0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7692307692307692"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "638f9133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_pred==y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e46f04",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
